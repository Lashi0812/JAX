{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using existing primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import traceback\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(14, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mul_add_lax(x, y, z):\n",
    "    return jax.lax.add(jax.lax.mul(x, y), z)\n",
    "\n",
    "\n",
    "def square_add_lax(x, y):\n",
    "    return mul_add_lax(x, x, y)\n",
    "\n",
    "\n",
    "square_add_lax(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(square_add_lax)(2.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper functions (execute this cell)\n",
    "import functools\n",
    "import traceback\n",
    "\n",
    "_indentation = 0\n",
    "def _trace(msg=None):\n",
    "    \"\"\"Print a message at current indentation.\"\"\"\n",
    "    if msg is not None:\n",
    "        print(\"  \" * _indentation + msg)\n",
    "\n",
    "def _trace_indent(msg=None):\n",
    "    \"\"\"Print a message and then indent the rest.\"\"\"\n",
    "    global _indentation\n",
    "    _trace(msg)\n",
    "    _indentation = 1 + _indentation\n",
    "\n",
    "def _trace_unindent(msg=None):\n",
    "    \"\"\"Unindent then print a message.\"\"\"\n",
    "    global _indentation\n",
    "    _indentation = _indentation - 1\n",
    "    _trace(msg)\n",
    "\n",
    "def trace(name):\n",
    "  \"\"\"A decorator for functions to trace arguments and results.\"\"\"\n",
    "\n",
    "  def trace_func(func):  # pylint: disable=missing-docstring\n",
    "    def pp(v):\n",
    "        \"\"\"Print certain values more succinctly\"\"\"\n",
    "        vtype = str(type(v))\n",
    "        if \"jax._src.xla_bridge._JaxComputationBuilder\" in vtype:\n",
    "            return \"<JaxComputationBuilder>\"\n",
    "        elif \"jaxlib.xla_extension.XlaOp\" in vtype:\n",
    "            return \"<XlaOp at 0x{:x}>\".format(id(v))\n",
    "        elif (\"partial_eval.JaxprTracer\" in vtype or\n",
    "              \"batching.BatchTracer\" in vtype or\n",
    "              \"ad.JVPTracer\" in vtype):\n",
    "            return \"Traced<{}>\".format(v.aval)\n",
    "        elif isinstance(v, tuple):\n",
    "            return \"({})\".format(pp_values(v))\n",
    "        else:\n",
    "            return str(v)\n",
    "    def pp_values(args):\n",
    "        return \", \".join([pp(arg) for arg in args])\n",
    "    \n",
    "    @functools.wraps(func)\n",
    "    def func_wrapper(*args):\n",
    "      _trace_indent(\"call {}({})\".format(name, pp_values(args)))\n",
    "      res = func(*args)\n",
    "      _trace_unindent(\"|<- {} = {}\".format(name, pp(res)))\n",
    "      return res\n",
    "\n",
    "    return func_wrapper\n",
    "\n",
    "  return trace_func\n",
    "\n",
    "class expectNotImplementedError(object):\n",
    "  \"\"\"Context manager to check for NotImplementedError.\"\"\"\n",
    "  def __enter__(self): pass\n",
    "  def __exit__(self, type, value, tb):\n",
    "    global _indentation\n",
    "    _indentation = 0\n",
    "    if type is NotImplementedError:\n",
    "      print(\"\\nFound expected exception:\")\n",
    "      traceback.print_exc(limit=3)\n",
    "      return True\n",
    "    elif type is None:  # No exception\n",
    "      assert False, \"Expected NotImplementedError\"\n",
    "    else:\n",
    "      return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import core\n",
    "multiply_add_p = core.Primitive(\"multiply_add\")  # Create the primitive\n",
    "\n",
    "# @trace(\"multiply_add_prim\")\n",
    "def multiply_add_prim(x, y, z):\n",
    "  \"\"\"The JAX-traceable way to use the JAX primitive.\n",
    "  \n",
    "  Note that the traced arguments must be passed as positional arguments\n",
    "  to `bind`. \n",
    "  \"\"\"\n",
    "  return multiply_add_p.bind(x, y, z)\n",
    "\n",
    "# @trace(\"square_add_prim\")\n",
    "def square_add_prim(a, b):\n",
    "  \"\"\"A square-add function implemented using the new JAX-primitive.\"\"\"\n",
    "  return multiply_add_prim(a, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_30442/2844449444.py\", line 2, in <module>\n",
      "    square_add_prim(2., 10.)\n",
      "  File \"/tmp/ipykernel_30442/1717318103.py\", line 16, in square_add_prim\n",
      "    return multiply_add_prim(a, a, b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_30442/1717318103.py\", line 11, in multiply_add_prim\n",
      "    return multiply_add_p.bind(x, y, z)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "NotImplementedError: Evaluation rule for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "with expectNotImplementedError():\n",
    "  square_add_prim(2., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_impl(x, y, z)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from jax import lax\n",
    "from jax._src import api\n",
    "\n",
    "# @trace(\"multiply_add_impl\")\n",
    "def multiply_add_impl(x, y, z):\n",
    "  \"\"\"Concrete implementation of the primitive.\n",
    "\n",
    "  This function does not need to be JAX traceable.\n",
    "  Args:\n",
    "    x, y, z: the concrete arguments of the primitive. Will only be called with \n",
    "      concrete values.\n",
    "  Returns:\n",
    "    the concrete result of the primitive.\n",
    "  \"\"\"\n",
    "  # Note that we can use the original numpy, which is not JAX traceable\n",
    "  return np.add(np.multiply(x, y), z)\n",
    "\n",
    "# Now we register the primal implementation with JAX\n",
    "multiply_add_p.def_impl(multiply_add_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert square_add_prim(2., 10.) == 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_30442/1813425700.py\", line 2, in <module>\n",
      "    api.jit(square_add_prim)(2., 10.)\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/traceback_util.py\", line 179, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/pjit.py\", line 257, in cache_miss\n",
      "    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^\n",
      "NotImplementedError: Abstract evaluation for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "with expectNotImplementedError():\n",
    "  api.jit(square_add_prim)(2., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_abstract_eval(xs, ys, zs)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import core\n",
    "# @trace(\"multiply_add_abstract_eval\")\n",
    "def multiply_add_abstract_eval(xs, ys, zs):\n",
    "  \"\"\"Abstract evaluation of the primitive.\n",
    "\n",
    "  This function does not need to be JAX traceable. It will be invoked with\n",
    "  abstractions of the actual arguments. \n",
    "  Args:\n",
    "    xs, ys, zs: abstractions of the arguments.\n",
    "  Result:\n",
    "    a ShapedArray for the result of the primitive.\n",
    "  \"\"\"\n",
    "  assert xs.shape == ys.shape\n",
    "  assert xs.shape == zs.shape\n",
    "  return core.ShapedArray(xs.shape, xs.dtype)\n",
    "\n",
    "# Now we register the abstract evaluation with JAX\n",
    "multiply_add_p.def_abstract_eval(multiply_add_abstract_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: MLIR translation rule for primitive 'multiply_add' not found for platform cpu\n",
      "\n",
      "The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n",
      "\n",
      "--------------------\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_30442/1813425700.py\", line 2, in <module>\n",
      "    api.jit(square_add_prim)(2., 10.)\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/traceback_util.py\", line 179, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/pjit.py\", line 257, in cache_miss\n",
      "    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^\n",
      "NotImplementedError: MLIR translation rule for primitive 'multiply_add' not found for platform cpu\n"
     ]
    }
   ],
   "source": [
    "with expectNotImplementedError():\n",
    "  api.jit(square_add_prim)(2., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_lowering(ctx, xc, yc, zc)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax._src.lib.mlir.dialects import hlo\n",
    "# @trace(\"multiply_add_lowering\")\n",
    "def multiply_add_lowering(ctx, xc, yc, zc):\n",
    "  \"\"\"The compilation to XLA of the primitive.\n",
    "\n",
    "  Given an mlir.ir.Value for each argument, return the mlir.ir.Values for\n",
    "  the results of the function.\n",
    "\n",
    "  Does not need to be a JAX-traceable function.\n",
    "  \"\"\"\n",
    "  return [hlo.AddOp(hlo.MulOp(xc, yc), zc).result]\n",
    "\n",
    "# Now we register the lowering rule with JAX\n",
    "# For GPU see the [Custom operations for GPUs](https://jax.readthedocs.io/en/latest/Custom_Operation_for_GPUs.html)\n",
    "# TODO: TPU?\n",
    "from jax.interpreters import mlir\n",
    "mlir.register_lowering(multiply_add_p, multiply_add_lowering, platform='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert api.jit(lambda x, y: square_add_prim(x, y))(2., 10.) == 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert api.jit(lambda x, y: square_add_prim(x, y), \n",
    "               static_argnums=1)(2., 10.) == 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_30442/800067577.py\", line 5, in <module>\n",
      "    api.jvp(square_add_prim, (2., 10.), (1., 1.))\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/api.py\", line 1945, in jvp\n",
      "    return _jvp(lu.wrap_init(fun), primals, tangents, has_aux=has_aux)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/api.py\", line 1974, in _jvp\n",
      "    out_primals, out_tangents = ad.jvp(flat_fun).call_wrapped(ps_flat, ts_flat)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "NotImplementedError: Differentiation rule for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "# The second argument `(2., 10.)` are the argument values\n",
    "# where we evaluate the Jacobian, and the third `(1., 1.)`\n",
    "# are the values of the tangents for the arguments.\n",
    "with expectNotImplementedError():\n",
    "  api.jvp(square_add_prim, (2., 10.), (1., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.interpreters import ad\n",
    "\n",
    "\n",
    "# @trace(\"multiply_add_value_and_jvp\")\n",
    "def multiply_add_value_and_jvp(arg_values, arg_tangents):\n",
    "  \"\"\"Evaluates the primal output and the tangents (Jacobian-vector product).\n",
    "\n",
    "  Given values of the arguments and perturbation of the arguments (tangents), \n",
    "  compute the output of the primitive and the perturbation of the output.\n",
    "\n",
    "  This method must be JAX-traceable. JAX may invoke it with abstract values \n",
    "  for the arguments and tangents.\n",
    "\n",
    "  Args:\n",
    "    arg_values: a tuple of arguments\n",
    "    arg_tangents: a tuple with the tangents of the arguments. The tuple has \n",
    "      the same length as the arg_values. Some of the tangents may also be the \n",
    "      special value ad.Zero to specify a zero tangent.\n",
    "  Returns:\n",
    "     a pair of the primal output and the tangent.\n",
    "  \"\"\"\n",
    "  x, y, z = arg_values\n",
    "  xt, yt, zt = arg_tangents\n",
    "  _trace(\"Primal evaluation:\")\n",
    "  # Now we have a JAX-traceable computation of the output. \n",
    "  # Normally, we can use the ma primitive itself to compute the primal output. \n",
    "  primal_out = multiply_add_prim(x, y, z)\n",
    "  \n",
    "  _trace(\"Tangent evaluation:\")\n",
    "  # We must use a JAX-traceable way to compute the tangent. It turns out that \n",
    "  # the output tangent can be computed as (xt * y + x * yt + zt),\n",
    "  # which we can implement in a JAX-traceable way using the same \"multiply_add_prim\" primitive.\n",
    "  \n",
    "  # We do need to deal specially with Zero. Here we just turn it into a \n",
    "  # proper tensor of 0s (of the same shape as 'x'). \n",
    "  # An alternative would be to check for Zero and perform algebraic \n",
    "  # simplification of the output tangent computation.\n",
    "  def make_zero(tan):\n",
    "    return lax.zeros_like_array(x) if type(tan) is ad.Zero else tan  \n",
    "  \n",
    "  output_tangent = multiply_add_prim(make_zero(xt), y, multiply_add_prim(x, make_zero(yt), make_zero(zt)))\n",
    "  return (primal_out, output_tangent)\n",
    "\n",
    "# Register the forward differentiation rule with JAX \n",
    "ad.primitive_jvps[multiply_add_p] = multiply_add_value_and_jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primal evaluation:\n",
      "Tangent evaluation:\n"
     ]
    }
   ],
   "source": [
    "# Tangent is: xt*y + x*yt + zt = 1.*2. + 2.*1. + 1. = 5.\n",
    "assert api.jvp(square_add_prim, (2., 10.), (1., 1.)) == (14., 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primal evaluation:\n",
      "Tangent evaluation:\n"
     ]
    }
   ],
   "source": [
    "assert api.jit(lambda arg_values, arg_tangents: \n",
    "                   api.jvp(square_add_prim, arg_values, arg_tangents))(\n",
    "         (2., 10.), (1., 1.)) == (14., 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primal evaluation:\n",
      "Tangent evaluation:\n",
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/interpreters/ad.py\", line 287, in get_primitive_transpose\n",
      "    return primitive_transposes[p]\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^\n",
      "KeyError: multiply_add\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented\n",
      "\n",
      "The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n",
      "\n",
      "--------------------\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_30442/339076514.py\", line 3, in <module>\n",
      "    api.grad(square_add_prim)(2., 10.)\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/traceback_util.py\", line 179, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/api.py\", line 659, in grad_f\n",
      "    _, g = value_and_grad_f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "# This is reverse differentiation w.r.t. the first argument of square_add_prim\n",
    "with expectNotImplementedError():\n",
    "  api.grad(square_add_prim)(2., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the new Primitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax._src.core.Primitive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_add_p = jax.core.Primitive(\"multiply_add\")\n",
    "type(multiply_add_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract_eval\n",
      "bind\n",
      "bind_with_trace\n",
      "call_primitive\n",
      "def_abstract_eval\n",
      "def_custom_bind\n",
      "def_effectful_abstract_eval\n",
      "def_impl\n",
      "get_bind_params\n",
      "impl\n",
      "map_primitive\n",
      "multiple_results\n",
      "name\n"
     ]
    }
   ],
   "source": [
    "for attr in dir(multiply_add_p):\n",
    "    if not attr.startswith(\"__\"):\n",
    "        print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_add_prim(x, y, z):\n",
    "    return multiply_add_p.bind(x, y, z)\n",
    "\n",
    "\n",
    "def square_add_prim(x, y):\n",
    "    return multiply_add_prim(x, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation rule for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    square_add_prim(2.0, 10.0)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Evaluation Rule and Register to primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_impl(x, y, z)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def multiply_add_impl(x, y, z):\n",
    "    \"\"\"Note we are using numpy here\"\"\"\n",
    "    return np.add(np.multiply(x, y), z)\n",
    "\n",
    "\n",
    "# register Eval rule to primitive\n",
    "multiply_add_p.def_impl(multiply_add_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert square_add_prim(2.0, 10.0) == 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract evaluation for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jax.jit(square_add_prim)(2.0, 10.0)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Abstraction Eval rule and Register to the primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_abstract_eval(xs, ys, zs)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply_add_abstract_eval(xs, ys, zs):\n",
    "    assert xs.shape == ys.shape\n",
    "    assert xs.shape == zs.shape\n",
    "    return jax.core.ShapedArray(xs.shape, xs.dtype)\n",
    "\n",
    "\n",
    "multiply_add_p.def_abstract_eval(multiply_add_abstract_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLIR translation rule for primitive 'multiply_add' not found for platform cpu\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jax.jit(square_add_prim)(2.0, 10.0)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLA Compilation Rule\n",
    "\n",
    "Jaxpr --> MLIR Lowering[HLO] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_lowering(ctx, xc, yc, zc)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax._src.lib.mlir.dialects import hlo\n",
    "from jax.interpreters import mlir\n",
    "\n",
    "def multiply_add_lowering(ctx, xc, yc, zc):\n",
    "    return [hlo.AddOp(hlo.MulOp(xc, yc), zc).result]\n",
    "\n",
    "\n",
    "\n",
    "mlir.register_lowering(multiply_add_p, multiply_add_lowering, platform=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(14., dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.jit(square_add_prim)(2.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differentiation rule for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jax.grad(square_add_prim)(2.0, 10.0)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'Callable',\n",
       " 'CustomJVPException',\n",
       " 'CustomVJPException',\n",
       " 'JVPTrace',\n",
       " 'JVPTracer',\n",
       " 'Literal',\n",
       " 'Partial',\n",
       " 'Primitive',\n",
       " 'Sequence',\n",
       " 'Trace',\n",
       " 'Tracer',\n",
       " 'UndefinedPrimal',\n",
       " 'Zero',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_closed_call_transpose',\n",
       " '_custom_lin_transpose',\n",
       " '_interleave',\n",
       " '_jvp_jaxpr',\n",
       " '_perm',\n",
       " '_primal_tangent_shapes_match',\n",
       " '_update_annotation',\n",
       " 'add_jaxvals',\n",
       " 'add_jaxvals_p',\n",
       " 'add_tangents',\n",
       " 'annotations',\n",
       " 'as_hashable_function',\n",
       " 'backward_pass',\n",
       " 'bilinear_transpose',\n",
       " 'call_p',\n",
       " 'call_param_updaters',\n",
       " 'call_transpose',\n",
       " 'call_transpose_param_updaters',\n",
       " 'closed_backward_pass',\n",
       " 'config',\n",
       " 'contextlib',\n",
       " 'core',\n",
       " 'custom_lin_p',\n",
       " 'defbilinear',\n",
       " 'defjvp',\n",
       " 'defjvp2',\n",
       " 'defjvp_zero',\n",
       " 'deflinear',\n",
       " 'deflinear2',\n",
       " 'dtype',\n",
       " 'f_jvp_traceable',\n",
       " 'flatten_fun',\n",
       " 'flatten_fun_nokwargs',\n",
       " 'float0',\n",
       " 'functools',\n",
       " 'get_aval',\n",
       " 'get_primitive_transpose',\n",
       " 'identity',\n",
       " 'instantiate_zeros',\n",
       " 'instantiate_zeros_aval',\n",
       " 'is_undefined_primal',\n",
       " 'it',\n",
       " 'jax',\n",
       " 'jvp',\n",
       " 'jvp_jaxpr',\n",
       " 'jvp_subtrace',\n",
       " 'jvp_subtrace_aux',\n",
       " 'jvpfun',\n",
       " 'linear_jvp',\n",
       " 'linear_transpose',\n",
       " 'linear_transpose2',\n",
       " 'linearize',\n",
       " 'lu',\n",
       " 'map',\n",
       " 'map_transpose',\n",
       " 'nonzero_outputs',\n",
       " 'nonzero_tangent_outputs',\n",
       " 'partial',\n",
       " 'partition_list',\n",
       " 'pe',\n",
       " 'primitive_jvps',\n",
       " 'primitive_transposes',\n",
       " 'raise_custom_vjp_error_on_jvp',\n",
       " 'raise_to_shaped',\n",
       " 'rearrange_binders',\n",
       " 'recast_to_float0',\n",
       " 'reducing_transposes',\n",
       " 'register_pytree_node',\n",
       " 'replace_float0s',\n",
       " 'replace_internal_symbolic_zeros',\n",
       " 'replace_rule_output_symbolic_zeros',\n",
       " 'safe_map',\n",
       " 'safe_zip',\n",
       " 'source_info_util',\n",
       " 'split_list',\n",
       " 'standard_jvp',\n",
       " 'standard_jvp2',\n",
       " 'traceable',\n",
       " 'tree_flatten',\n",
       " 'tree_unflatten',\n",
       " 'unpair_pval',\n",
       " 'unzip2',\n",
       " 'vjp',\n",
       " 'weakref_lru_cache',\n",
       " 'wrap_name',\n",
       " 'zero_jvp',\n",
       " 'zeros_like_aval',\n",
       " 'zeros_like_jaxval',\n",
       " 'zeros_like_p',\n",
       " 'zip']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax._src.interpreters import ad\n",
    "\n",
    "dir(ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.interpreters import ad\n",
    "\n",
    "def mul_add_value_and_jvp(arg_value, arg_tangent):\n",
    "    \"\"\"Function must jax traceable\"\"\"\n",
    "    x, y, z = arg_value\n",
    "    xt, yt, zt = arg_tangent\n",
    "    primal_out = multiply_add_prim(x,y,z)\n",
    "    def make_zero(tan):\n",
    "        return jax.lax.zeros_like_array(x) if type(tan) is ad.Zero else tan \n",
    "    \n",
    "    tangent_out = multiply_add_prim(make_zero(xt),y,multiply_add_prim(x,make_zero(yt),make_zero(zt)))\n",
    "    return (primal_out,tangent_out)\n",
    "\n",
    "ad.primitive_jvps[multiply_add_p] = mul_add_value_and_jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax._src import api\n",
    "assert api.jvp(square_add_prim, (2., 10.), (1., 1.)) == (14., 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert api.jit(lambda arg_values, arg_tangents: \n",
    "                   api.jvp(square_add_prim, arg_values, arg_tangents))(\n",
    "         (2., 10.), (1., 1.)) == (14., 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/interpreters/ad.py\", line 287, in get_primitive_transpose\n",
      "    return primitive_transposes[p]\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^\n",
      "KeyError: multiply_add\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented\n",
      "\n",
      "The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n",
      "\n",
      "--------------------\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_30442/846820585.py\", line 2, in <module>\n",
      "    jax.grad(square_add_prim)(2.,10.)\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/traceback_util.py\", line 179, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/api.py\", line 659, in grad_f\n",
      "    _, g = value_and_grad_f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/traceback_util.py\", line 179, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/envs/nlp/lib/python3.11/site-packages/jax/_src/api.py\", line 741, in value_and_grad_f\n",
      "    g = vjp_py(lax_internal._one(ans))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jax.grad(square_add_prim)(2.,10.)\n",
    "except Exception:\n",
    "    traceback.print_exc(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_add_transpose(ct,x,y,z):\n",
    "    if not ad.is_undefined_primal(x):\n",
    "        assert ad.is_undefined_primal(y)\n",
    "        ct_y = ad.Zero(y.aval) if type(ct) is ad.Zero else multiply_add_prim(x,ct,jax.lax.zeros_like_array(x))\n",
    "        res = None,ct_y,ct\n",
    "    else:\n",
    "        assert ad.is_undefined_primal(x)\n",
    "        ct_x = ad.Zero(x.aval) if type(ct) is ad.Zero else multiply_add_prim(ct,y,jax.lax.zeros_like_array(y))\n",
    "        res = ct_x,None,ct\n",
    "    return res\n",
    "\n",
    "ad.primitive_transposes[multiply_add_p] = multiply_add_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4., dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(square_add_prim)(2.0,10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching rule for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jax.vmap(square_add_prim,in_axes=0,out_axes=0)(np.array([2.,3.]),np.array([10.,20.]))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.interpreters import  batching\n",
    "\n",
    "def mul_add_batch(vector_arg_values,batch_axes):\n",
    "    assert batch_axes[0] == batch_axes[1]\n",
    "    assert batch_axes[0] == batch_axes[2]\n",
    "    res = multiply_add_prim(*vector_arg_values)\n",
    "    return res,batch_axes[0]\n",
    "\n",
    "batching.primitive_batchers[multiply_add_p] = mul_add_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 29.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.vmap(square_add_prim,in_axes=0,out_axes=0)(np.array([2.,3.]),np.array([10.,20.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
